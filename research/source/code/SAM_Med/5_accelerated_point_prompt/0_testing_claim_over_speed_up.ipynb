{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "\n",
    "The main limitation with the previous design was that the batches didn't fit neatly into\n",
    "memory, and a lot of overhead was required for loading upsampled slices. In addition to\n",
    "requiring a lot of memory and such, it is not feasible to expect fast performance. With\n",
    "annecdotal experience, some training datasets were around 300 GB, and with constant\n",
    "reading from disk etc. slows the entire system down.\n",
    "\n",
    "A solution was proposed by using a 'stochastic caching library' [linked\n",
    "here](https://github.com/Charl-AI/stochastic-caching) which would cache some intermediate\n",
    "results making them faster to access. However, with sizes like 300 GB the effects of this\n",
    "library are drowned out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import monai\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from time import time, sleep\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import SimpleITK as sitk \n",
    "from segment_anything import sam_model_registry\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Add the setup_data_vars function as we will need it to find the directory for the training data.\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..', '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "\n",
    "from utils.environment import setup_data_vars\n",
    "setup_data_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stocaching import SharedCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_to_load_all(dataloader):\n",
    "    # Measure the time to load all the data\n",
    "    start = time()\n",
    "    for data in tqdm(dataloader):\n",
    "        pass\n",
    "    end = time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_from_path(path, needs_num=True, pos = 0):\n",
    "    # Assume that it is the full path that points to the file name. The file name should\n",
    "    # contain a number indicating the id number. It should appear first\n",
    "    numbers = re.findall('\\d+', os.path.basename(path))\n",
    "    if needs_num and len(numbers) == 0:\n",
    "        raise ValueError(f\"Could not find a number in {path}\")\n",
    "    if not needs_num and len(numbers) <= pos:\n",
    "        return 0\n",
    "    return int(numbers[pos])\n",
    "assert get_id_from_path('radiotherapy/data/MedSAM_preprocessed/imgs/axis0/CT_zzAMLART_001-071.npy', False) == 1\n",
    "assert get_id_from_path('/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/MedSAM_preprocessed/gts/Bladder/axis0/CT_Bladder_zzAMLART_002-085.npy', False) == 2\n",
    "assert get_id_from_path('radiotherapy/data/nnUNet_raw/Dataset001_Anorectum/imagesTr/zzAMLART_003_0000.nii.gz', False) == 3\n",
    "assert get_id_from_path('/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/research/source/code/data/reports/reportAnorectum_axis0_1.png', False, pos=1) == 1\n",
    "def get_slice_from_path(path, isMedSAM = False):\n",
    "    # Assume that it is the full path that points to the file name. The file name should\n",
    "    # contain a number indicating the id number. It should appear first. The second number\n",
    "    # should be slice number\n",
    "    if 'MedSAM' not in path and not isMedSAM:\n",
    "        raise ValueError(f'Function intended for getting slice id from a path, which is only characteristic of MedSAM data')\n",
    "    numbers = re.findall('\\d+', path.split('/')[-1])\n",
    "    assert len(numbers) == 2, f\"Could not find a number in {path}\"\n",
    "    return int(numbers[1])\n",
    "assert get_slice_from_path('radiotherapy/data/MedSAM_preprocessed/imgs/axis0/CT_zzAMLART_001-071.npy') == 71\n",
    "assert get_slice_from_path('/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/MedSAM_preprocessed/gts/Bladder/axis0/CT_Bladder_zzAMLART_002-085.npy') == 85\n",
    "try: \n",
    "    get_slice_from_path('radiotherapy/data/nnUNet_raw/Dataset001_Anorectum/imagesTr/zzAMLART_003_0000.nii.gz')\n",
    "    assert False, 'Didn\\'t raise error as expected'\n",
    "except ValueError as e: assert str(e) == 'Function intended for getting slice id from a path, which is only characteristic of MedSAM data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the time to load a random slice from each image id using the MedSAM pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id_from_file_name_regex = r'.*_(\\d+).*'\n",
    "slice_id_from_file_name_regex = r'.*-(\\d+).*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEDSAM_DATASET_NO_CACHING(Dataset):\n",
    "    \"\"\"A torch dataset for delivering slices of any axis to a medsam model.\"\"\"\n",
    "\n",
    "    def __init__(self, img_path, gt_path,):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_path (string): Path to the directory containing the images\n",
    "            gt_path (string): Path to the directory containing the ground truth masks\n",
    "            id_split (list): List of image ids to include in the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        self.root_img_path = img_path\n",
    "        self.root_gt_path = gt_path\n",
    "        \n",
    "        # Assume that axese 0 1 and 2 have been processed.\n",
    "        filter_fn = lambda x : x.endswith('.npy')\n",
    "        self.axis0_imgs = list(filter(filter_fn, os.listdir(os.path.join(gt_path, 'axis0'))))\n",
    "        self.axis1_imgs = list(filter(filter_fn, os.listdir(os.path.join(gt_path, 'axis1'))))\n",
    "        self.axis2_imgs = list(filter(filter_fn, os.listdir(os.path.join(gt_path, 'axis2'))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.axis0_imgs) + len(self.axis1_imgs) + len(self.axis2_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert 0 <= idx < self.__len__(), f\"Index {idx} is out of range for dataset of size {self.__len__()}\"\n",
    "\n",
    "        # Fetch the image and ground truth mask. For safety, we index the items around the\n",
    "        # ground truth masks, so that if for some reason the images are misaligned we will\n",
    "        # guarantee that we will fetch the correct image\n",
    "\n",
    "        img_path, gt_path, img_name = self._get_image_and_gt_path(idx)\n",
    "\n",
    "        img = np.load(img_path, 'r', allow_pickle=True) # (H, W, C)\n",
    "        img = np.transpose(img, (2, 0, 1)) # (C, H, W)\n",
    "        assert np.max(img) <= 1. and np.min(img) >= 0., 'image should be normalized to [0, 1]'\n",
    "        \n",
    "        img = torch.tensor(img).float()\n",
    "        \n",
    "        # Loading of ground truth shouldn't be the limiting factor\n",
    "        gt = np.load(gt_path, 'r', allow_pickle=True) # (H, W, C)\n",
    "\n",
    "        gt = cv2.resize(\n",
    "            gt,\n",
    "            (256, 256),\n",
    "            interpolation=cv2.INTER_NEAREST\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"image\": img, # 3x1024x1024\n",
    "            \"gt2D\": torch.tensor(gt[None, :,:]).long(), # 1x256x256\n",
    "            \"image_name\": img_name\n",
    "        }\n",
    "    \n",
    "    def _get_image_and_gt_path(self, idx):\n",
    "        if idx < len(self.axis0_imgs):\n",
    "            axis, gt_name = 0, self.axis0_imgs[idx]\n",
    "        elif idx < len(self.axis0_imgs) + len(self.axis1_imgs):\n",
    "            axis, gt_name = 1, self.axis1_imgs[idx - len(self.axis0_imgs)]\n",
    "        else:\n",
    "            axis, gt_name = 2, self.axis2_imgs[idx - len(self.axis0_imgs) - len(self.axis1_imgs)]\n",
    "\n",
    "        image_id = int(re.search(image_id_from_file_name_regex, gt_name).group(1))\n",
    "        slice_id = int(re.search(slice_id_from_file_name_regex, gt_name).group(1))\n",
    "\n",
    "        img_name = f'CT_zzAMLART_{image_id:03d}-{slice_id:03d}.npy'\n",
    "        \n",
    "        img_path = os.path.join(self.root_img_path, f'axis{axis}', img_name)\n",
    "        gt_path = os.path.join(self.root_gt_path, f'axis{axis}', gt_name)\n",
    "\n",
    "        return img_path, gt_path, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = MEDSAM_DATASET_NO_CACHING(\n",
    "    os.path.join(os.environ.get('MedSAM_preprocessed'), 'imgs'), \n",
    "    os.path.join(os.environ.get('MedSAM_preprocessed'), 'gts', 'CTVn')  # annecdotally, the CTVn contains the most masks, and therefore is taken as an upper bound\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataloader = DataLoader(my_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 39/2105 [05:17<4:40:23,  8.14s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmeasure_time_to_load_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36mmeasure_time_to_load_all\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure_time_to_load_all\u001b[39m(dataloader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Measure the time to load all the data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     end \u001b[38;5;241m=\u001b[39m time()\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m, in \u001b[0;36mMEDSAM_DATASET_NO_CACHING.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(img_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# (H, W, C)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(img, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# (C, H, W)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(img) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage should be normalized to [0, 1]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     37\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(img)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Loading of ground truth shouldn't be the limiting factor\u001b[39;00m\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2810\u001b[0m, in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[1;32m   2693\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2694\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2695\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2697\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2698\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_maximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/memmap.py:319\u001b[0m, in \u001b[0;36mmemmap.__array_wrap__\u001b[0;34m(self, arr, context)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_wrap__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arr, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__array_wrap__(arr, context)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# Return a memmap if a memmap was given as the output of the\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# ufunc. Leave the arr class unchanged if self is not a memmap\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;66;03m# to keep original memmap subclasses behavior\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "measure_time_to_load_all(my_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the time to load a random slice from each image id using the .nii.gz raw data-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAW_DATASET_WITH_CACHING(Dataset):\n",
    "    \"\"\"A torch dataset for delivering slices of any axis to a medsam model.\"\"\"\n",
    "\n",
    "    def __init__(self, medsam_gt_path, raw_img_path, raw_gt_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_path (string): Path to the directory containing the images\n",
    "            gt_path (string): Path to the directory containing the ground truth masks\n",
    "            id_split (list): List of image ids to include in the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        self.root_img_path = raw_img_path\n",
    "        self.root_gt_path = raw_gt_path\n",
    "        \n",
    "        # Read in the ground truths. This has been a pre-processed step so we utilize it.\n",
    "        # These tell us which slices of the images contain the contoured area. It is a\n",
    "        # fair comparison becuase MedSAM operates on pre-processed data, thus we maximise\n",
    "        # this ability with raw data also.\n",
    "        filter_fn = lambda x : x.endswith('.npy')\n",
    "        self.axis0_imgs = list(filter(filter_fn, os.listdir(os.path.join(medsam_gt_path, 'axis0'))))\n",
    "        self.axis1_imgs = list(filter(filter_fn, os.listdir(os.path.join(medsam_gt_path, 'axis1'))))\n",
    "        self.axis2_imgs = list(filter(filter_fn, os.listdir(os.path.join(medsam_gt_path, 'axis2'))))\n",
    "\n",
    "        # pre-process this to create a dictionary of image ids and the slices that contain\n",
    "        # the contoured area\n",
    "\n",
    "        self.id_to_slice_dict_axis0 = dict([(i, []) for i in range(1, 101)])\n",
    "        self.id_to_slice_dict_axis1 = dict([(i, []) for i in range(1, 101)])\n",
    "        self.id_to_slice_dict_axis2 = dict([(i, []) for i in range(1, 101)])\n",
    "        \n",
    "        def populate(id_to_slice_dict, axis_imgs):\n",
    "            for img in axis_imgs:\n",
    "                image_id = get_id_from_path(img)\n",
    "                slice_id = get_slice_from_path(img)\n",
    "                id_to_slice_dict[image_id].append(slice_id)\n",
    "\n",
    "        populate(self.id_to_slice_dict_axis0, self.axis0_imgs)\n",
    "        populate(self.id_to_slice_dict_axis1, self.axis1_imgs)\n",
    "        populate(self.id_to_slice_dict_axis2, self.axis2_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.axis0_imgs) + len(self.axis1_imgs) + len(self.axis2_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert 0 <= idx < self.__len__(), f\"Index {idx} is out of range for dataset of size {self.__len__()}\"\n",
    "\n",
    "        # Fetch the image and ground truth mask. For safety, we index the items around the\n",
    "        # ground truth masks, so that if for some reason the images are misaligned we will\n",
    "        # guarantee that we will fetch the correct image\n",
    "\n",
    "        img_path, gt_path, slice_index, axis = self._get_image_and_gt_path(idx)\n",
    "\n",
    "        raw_image = sitk.ReadImage(img_path)\n",
    "        raw_image_array = sitk.GetArrayFromImage(raw_image)\n",
    "\n",
    "        raw_gt = sitk.ReadImage(gt_path)\n",
    "        raw_gt_array = sitk.GetArrayFromImage(raw_gt)\n",
    "\n",
    "        # read in the slice for both arrays\n",
    "\n",
    "        slices = [slice(None)] * 3\n",
    "        slices[axis] = slice_index\n",
    "        slices = tuple(slices)\n",
    "\n",
    "        img = raw_image_array[slices]\n",
    "        img = np.transpose(img, (2, 0, 1)) # (C, H, W)\n",
    "\n",
    "        img = np.load(img_path, 'r', allow_pickle=True) # (H, W, C)\n",
    "        img = np.transpose(img, (2, 0, 1)) # (C, H, W)\n",
    "        assert np.max(img) <= 1. and np.min(img) >= 0., 'image should be normalized to [0, 1]'\n",
    "        \n",
    "        img = torch.tensor(img).float()\n",
    "        \n",
    "        # Loading of ground truth shouldn't be the limiting factor\n",
    "        gt = np.load(gt_path, 'r', allow_pickle=True) # (H, W, C)\n",
    "\n",
    "        gt = cv2.resize(\n",
    "            gt,\n",
    "            (256, 256),\n",
    "            interpolation=cv2.INTER_NEAREST\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"image\": img, # 3x1024x1024\n",
    "            \"gt2D\": torch.tensor(gt[None, :,:]).long(), # 1x256x256\n",
    "            \"image_name\": img_name\n",
    "        }\n",
    "    \n",
    "    def _get_image_and_gt_path(self, idx):\n",
    "        \"\"\"Returns the paths for the image and ground truth mask for the given index and\n",
    "        also the slice index and axis\"\"\"\n",
    "\n",
    "        if idx < len(self.axis0_imgs):\n",
    "            axis, gt_name = 0, self.axis0_imgs[idx]\n",
    "        elif idx < len(self.axis0_imgs) + len(self.axis1_imgs):\n",
    "            axis, gt_name = 1, self.axis1_imgs[idx - len(self.axis0_imgs)]\n",
    "        else:\n",
    "            axis, gt_name = 2, self.axis2_imgs[idx - len(self.axis0_imgs) - len(self.axis1_imgs)]\n",
    "\n",
    "        image_id = get_id_from_path(gt_name)\n",
    "        slice_id = get_slice_from_path(gt_name)\n",
    "\n",
    "        image_path = os.path.join(self.raw_img_path, 'zzAMLART_{:03d}_0000.nii.gz'.format(image_id))\n",
    "        gt_path = os.path.join(self.raw_gt_path, 'zzAMLART_{:03d}.nii.gz'.format(image_id))\n",
    "\n",
    "        return image_path, gt_path, slice_id, axis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
